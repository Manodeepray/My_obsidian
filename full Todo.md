- [ ] llm engineering[[llm engineers handbook.pdf]]
	- [x] 1
	- [x] 2
	- [ ] 3
	- [ ] 4
	- [ ] 5
	- [ ] 6
	- [ ] 7
	- [ ] 8
	- [ ] 9
	- [ ] 10
	- [ ] 11
- [ ] ml sys [[ml systems.pdf]]
	- [ ] 
- [ ] llm course [[My_obsidian/summer_progress/LLMS|LLMS]]
	- [ ] week 2
	- [ ] week 3
	- [ ] week 4
	- [ ] project main
	- [ ] offloading project
- [ ] maths [[mathematics for ML.pdf]]
- [ ] DSA
	- [x] array 
		- [ ] hard
		- [x] medium
	- [ ] 15 algorithms 
		- [x] sliding window 
		- [ ] https://www.youtube.com/watch?v=pBWCOCS636U&list=PLgUwDviBIf0q7vrFA_HEWcqRqMpCXzYAL&index=2
		- [x] 2 pointer
		- [ ] 
	- [ ] linked list
	- [x] hashing
	- [ ] recursion
- [ ] Aptitude
	- [ ] advance
		- [ ] hcf lcm
		- [ ] num system
- [ ] GK
	- [ ] college
	- [ ] world


 Backend Engineer [[systems_design_interview.pdf]]
        âˆŸAPI Design & REST & grpc
        âˆŸ Databases
            âˆŸ PostgreSQL / MongoDB
        âˆŸ Authentication & Authorization
        âˆŸ Background Jobs & Queues
        âˆŸ Docker & CI/CD
        âˆŸ Cloud (AWS / Azure / GCP)
        âˆŸ Caching (Redis, Memcached)
        âˆŸ Observability & Logging
        âˆŸ System Design
        âˆŸ Programming Language
            âˆŸ  Python / Go / JavaScript (Start HERE)


[[My_obsidian/summer_progress/LLMS|LLMS]]
Challenges:
1. Convert nf4 / BnB 4bit to Triton
2. Make FSDP2 work with QLoRA
3. Remove graph breaks in torch.compile
4. Memory Efficient Backprop




GRPO trainer 
all the different paradigms too -- layer norm

## ðŸ§  Missing Projects (You Should Add):

1. **Custom LLM Fine-tuning Project**
    
    - Take a small domain dataset (e.g., resume screening, legal, FAQ) and fine-tune a small LLM.
    - Add RLHF or quantization if possible.
        
2. **Model Optimization Pipeline**
    
    - Show your ability to convert models to ONNX, optimize with TensorRT, and benchmark them on CPU vs GPU vs edge.
        
---

## ðŸ”§ Additional Skill Suggestions for ML/DL Roles

- **Docker** (highly expected for deployment)
    
- **Model Serving (ONNX, TorchServe, TensorRT)**
    
- **MLFlow or Weights & Biases** for experiment tracking
    
- **Parallel processing (multiprocessing, CUDA kernels)**    

- **NLP**: ==LoRA==, QLoRA, PEFT fine-tuning
    
- **Prompt Engineering & LLM Evaluation**