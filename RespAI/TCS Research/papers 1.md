# param efficent alts

https://huggingface.co/docs/trl/main/en/lora_without_regret

[antidote](https://arxiv.org/pdf/2509.08000)

- [x] [https://arxiv.org/html/2310.01405v4](https://arxiv.org/html/2310.01405v4) repe
- [x] [https://arxiv.org/pdf/2404.03592](https://arxiv.org/pdf/2404.03592) reft - loreft [[ReFT]]
- [x] [https://arxiv.org/pdf/2406.01563](https://arxiv.org/pdf/2406.01563) lofit
- [x] [https://arxiv.org/pdf/2312.00700](https://arxiv.org/pdf/2312.00700) wegeft
- [ ] [https://asta.allen.ai/chat/d3155a63-090d-451d-b694-916c5ce1a290](https://asta.allen.ai/chat/d3155a63-090d-451d-b694-916c5ce1a290)
- [ ] lora vs full finetuning
- [ ] spice
- [ ] INTRINSIC DIMENSIONALITY EXPLAINS THE EFFECTIVENESS OF LANGUAGE MODEL FINE-TUNING
- [ ] influence functions for time series 
	- [ ] https://projecteuclid.org/journalArticle/Download?urlId=10.1214%2Faos%2F1176350027
- [ ] Bridging the Gap Between Preference Alignment and Machine Unlearning
- [ ] DATAINF: EFFICIENTLY ESTIMATING DATA INFLUENCE
- [ ] Characterizations of an Empirical Influence
- [ ] REVISIT, EXTEND, AND ENHANCE HESSIAN-FREE INFLUENCE
- [ ] Negative Preference Optimization: From Catastrophic Collapse
- [ ] On Differentiating Parameterized Argmin and Argmax Problems
- [ ] Evaluating Deep Unlearning in Large Language
- [ ] # Deep Unlearning: Fast and Efficient Gradient-free Approach to Class Forgetting
- [ ] Understanding and Mitigating the Tradeoff Between Robustness and Accuracy
- [ ] tamper res
	- [ ] Vaccine: Perturbation-aware Alignment for Large
- [ ] tokenization
	- [x] on policy distillation
	- [ ] gkd
	- [x] uld
- [ ] Finding Alignments Between Interpretable
- [ ] hyper networks
	- [ ] hyperlora
- [ ] UNDIAL https://assets.amazon.science/eb/81/936bf1a0479f9b41b71053699166/undial-self-distillation-with-adjusted-logits-for-robust-unlearning-in-large-language-models.pdf
- [ ] 



npo dpo perturbation canary new


influlence




