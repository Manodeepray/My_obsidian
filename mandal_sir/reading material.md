[Multimodal Chain-of-Thought Reasoning in Language Models](https://arxiv.org/abs/2302.00923#:~:text=Large%20language%20models%20(LLMs)%20have,rationale%20to%20infer%20the%20answer.)

[Representation noising effectively prevents harmful fine-tuning on LLMs](https://arxiv.org/abs/2405.14577)

[Erasing Conceptual Knowledge from Language Models](https://arxiv.org/abs/2410.02760)

[Eight Methods to Evaluate Robust Unlearning in LLMs](https://arxiv.org/abs/2402.16835)

[Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?](https://arxiv.org/abs/2405.05904)

[# Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous Prompt Learning](https://arxiv.org/abs/2405.03279)

[# Fine-grained Hallucination Detection and Editing for Language Models](https://arxiv.org/abs/2401.06855)

[# Logic-of-Thought: Injecting Logic into Contexts for Full Reasoning in Large Language Models](https://arxiv.org/abs/2409.17539) -  [medium blog on LoT]( https://medium.com/@techsachin/logic-of-thought-prompting-approach-leveraging-propositional-logic-to-enhance-logical-reasoning-f15fe50d909a) , [twitter post by RohanPaul](https://x.com/rohanpaul_ai/status/1842366845040398409)

[Were RNNs All We Needed](https://arxiv.org/abs/2410.01201)




